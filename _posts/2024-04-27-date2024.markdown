---
layout: post
title:  "DAISM: Digital Approximate In-SRAM Multiplier-based Accelerator for DNN Training and Inference"
date:   2024-01-12
image: /images/date-2024.png
categories: research
author: "Shaswot Shresthamali"
authors: Lorenzo Sonnino, <strong>Shaswot Shresthamali</strong>, Yuan He, and Masaaki Kondo
venue: "2024 Design, Automation and Test in Europe Conference (DATE 2024)"
arxiv: https://arxiv.org/abs/2305.07376
link: https://doi.org/10.23919/DATE58400.2024.10546578
slides:
paper: /pdfs/date-2025-paper.pdf 
video: 
code:
---
DNNs are widely used but face significant computational costs due to matrix multiplications, especially from data movement between the memory and processing units. One promising approach is therefore Processing-in-Memory as it greatly reduces this overhead. However, most PIM solutions rely either on novel memory technologies that have yet to mature or bit-serial computations that have significant performance overhead and scalability issues. Our work proposes an in-SRAM digital multiplier, that uses a conventional memory to perform bit-parallel computations, leveraging multiple wordlines activation. We then introduce DAISM, an architecture leveraging this multiplier, which achieves up to two orders of magnitude higher area efficiency compared to the SOTA counterparts, with competitive energy efficiency.
